{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/c_spino/comp_550/comp-550-project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.json_utils import read_json_lines\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import copy\n",
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smokers data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "current-smoker     46\n",
       "non-smoker         82\n",
       "past-smoker        47\n",
       "smoker             12\n",
       "unknown           315\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = read_json_lines(os.path.join(cur_dir,\"..\", \"data/smokers/augmentation/train.json\"))\n",
    "val = read_json_lines(os.path.join(cur_dir, \"..\", \"data/smokers/augmentation/validation.json\"))\n",
    "test = read_json_lines(os.path.join(cur_dir, \"..\", \"data/smokers/augmentation/test.json\"))\n",
    "train = pd.DataFrame(data={\"label\": [x[\"label\"] for x in train], \"text\": [x[\"text\"] for x in train]})\n",
    "val = pd.DataFrame(data={\"label\": [x[\"label\"] for x in val], \"text\": [x[\"text\"] for x in val]})\n",
    "test = pd.DataFrame(data={\"label\": [x[\"label\"] for x in test], \"text\": [x[\"text\"] for x in test]})\n",
    "all_data = pd.concat([train, val, test])\n",
    "SMOKERS = {\n",
    "    \"unknown\": 0,\n",
    "    \"non-smoker\": 1,\n",
    "    \"past-smoker\": 2,\n",
    "    \"smoker\": 3,\n",
    "    \"current-smoker\": 4,\n",
    "}\n",
    "SMOKERS_INVERSE = dict(zip(SMOKERS.values(), SMOKERS.keys()))\n",
    "all_data.groupby(\"label\").size()\n",
    "all_data.replace(SMOKERS_INVERSE).groupby(\"label\").size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DA Performance for BoW models\n",
    "Manual extraction from the logs is required for the test $F_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the macro average f1 based on confusion matrix\n",
    "def compute_f1(confusion_matrix):\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    FP = np.sum(confusion_matrix, axis=0) - TP\n",
    "    FN = np.sum(confusion_matrix, axis=1) - TP\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    TN = []\n",
    "    for i in range(num_classes):\n",
    "        temp = np.delete(confusion_matrix, i, 0)  # delete ith row\n",
    "        temp = np.delete(temp, i, 1)  # delete ith column\n",
    "        TN.append(sum(sum(temp)))\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = 2*(precision*recall)/(precision+recall)\n",
    "    F1 = np.nan_to_num(F1)\n",
    "    macro_f1 = F1.mean()\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c_spino/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/home/c_spino/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Read the performance\n",
    "polarity_results = read_json_lines(os.path.join(cur_dir, \"..\", \"logs/training/polarity_constant.json\"))\n",
    "articles_results = read_json_lines(os.path.join(cur_dir, \"..\", \"logs/training/articles_constant.json\"))\n",
    "smokers_results = read_json_lines(os.path.join(cur_dir, \"..\", \"logs/training/smokers_constant.json\"))\n",
    "# Convert to dataframe\n",
    "polarity_results = pd.DataFrame(polarity_results)\n",
    "articles_results = pd.DataFrame(articles_results)\n",
    "smokers_results = pd.DataFrame(smokers_results)\n",
    "# Drop the pickle path\n",
    "polarity_results.drop(columns=[\"path_to_pickle\"], inplace=True)\n",
    "articles_results.drop(columns=[\"path_to_pickle\"], inplace=True)\n",
    "smokers_results.drop(columns=[\"path_to_pickle\"], inplace=True)\n",
    "data_types = [\"polarity\", \"articles\", \"smokers\"]\n",
    "reshape_size = {\"polarity\": 2, \"articles\": 5, \"smokers\": 3}\n",
    "data_dict_svm = {}\n",
    "for data_type in data_types:\n",
    "    # Add the test f1 from the logs using re\n",
    "    # (because I mistakenly did not add these to the json!!!!)\n",
    "    with open(os.path.join(cur_dir, \"..\", f\"logs/training/{data_type}_constant.log\"), \"r\") as f:\n",
    "        text = f.read()\n",
    "        results = re.findall(r\"(\\[\\[(.*\\n\\s.*)*\\]\\])\", text)\n",
    "    results = [x[0] for x in results]\n",
    "    results = [x.replace(\"\\n \", \" \") for x in results]\n",
    "    results = [x.replace(\"[\", \"\").replace(\"]\", \"\") for x in results]\n",
    "    results = [np.fromstring(x, dtype=np.int64, sep=\" \").reshape(-1, reshape_size[data_type]) for x in results]\n",
    "    # Get the aug info\n",
    "    data = []\n",
    "    with open(os.path.join(cur_dir, \"..\", f\"logs/training/{data_type}_constant.log\"), \"r\") as f:\n",
    "        dict_ = {}\n",
    "        for i, line in enumerate(f):\n",
    "            if \"with augmentation\" in line.lower():\n",
    "                result = re.match(r\".*with augmentation (\\d+)\", line)\n",
    "                dict_[\"augmentation_id\"] = int(result.group(1))\n",
    "            if \"augmentation features\" in line.lower():\n",
    "                result = re.match(r\".*Augmentation features: (.*)\", line)\n",
    "                dict_[\"augmentation_features\"] = ast.literal_eval(result.group(1))\n",
    "                data.append(dict_)\n",
    "                dict_ = {}\n",
    "    # Get the test f1\n",
    "    for i in range(len(data)):\n",
    "        data[i][\"nb_f1\"] = compute_f1(results[6*i + 1])\n",
    "        data[i][\"lr_f1\"] = compute_f1(results[6*i + 3])\n",
    "        data[i][\"svm_f1\"] = compute_f1(results[6*i + 5])\n",
    "    data = pd.DataFrame(data)\n",
    "    data_dict_svm[data_type] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>nb_f1</th>\n",
       "      <th>lr_f1</th>\n",
       "      <th>svm_f1</th>\n",
       "      <th>svm_f1_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>0.804025</td>\n",
       "      <td>0.766238</td>\n",
       "      <td>0.768327</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.775894</td>\n",
       "      <td>0.783334</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.779728</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.788939</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.789984</td>\n",
       "      <td>0.775929</td>\n",
       "      <td>0.785331</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.773090</td>\n",
       "      <td>0.768246</td>\n",
       "      <td>0.792667</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.785252</td>\n",
       "      <td>0.765589</td>\n",
       "      <td>0.778763</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.789092</td>\n",
       "      <td>0.775065</td>\n",
       "      <td>0.766595</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.783468</td>\n",
       "      <td>0.767465</td>\n",
       "      <td>0.782499</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.790859</td>\n",
       "      <td>0.763714</td>\n",
       "      <td>0.783444</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.781569</td>\n",
       "      <td>0.758068</td>\n",
       "      <td>0.774105</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.779707</td>\n",
       "      <td>0.775515</td>\n",
       "      <td>0.788769</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.783486</td>\n",
       "      <td>0.784124</td>\n",
       "      <td>0.789888</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.766635</td>\n",
       "      <td>0.775874</td>\n",
       "      <td>0.767527</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "2                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "8                 8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "9                 9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "10               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "11               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "12               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "       nb_f1     lr_f1    svm_f1  svm_f1_round  \n",
       "0   0.804025  0.766238  0.768327         0.768  \n",
       "1   0.782484  0.775894  0.783334         0.783  \n",
       "2   0.779728  0.775806  0.788939         0.789  \n",
       "3   0.789984  0.775929  0.785331         0.785  \n",
       "4   0.773090  0.768246  0.792667         0.793  \n",
       "5   0.785252  0.765589  0.778763         0.779  \n",
       "6   0.789092  0.775065  0.766595         0.767  \n",
       "7   0.783468  0.767465  0.782499         0.782  \n",
       "8   0.790859  0.763714  0.783444         0.783  \n",
       "9   0.781569  0.758068  0.774105         0.774  \n",
       "10  0.779707  0.775515  0.788769         0.789  \n",
       "11  0.783486  0.784124  0.789888         0.790  \n",
       "12  0.766635  0.775874  0.767527         0.768  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_svm[\"polarity\"][\"svm_f1_round\"] = np.round(data_dict_svm[\"polarity\"][\"svm_f1\"], decimals=3)\n",
    "data_dict_svm[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>nb_f1</th>\n",
       "      <th>lr_f1</th>\n",
       "      <th>svm_f1</th>\n",
       "      <th>svm_f1_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>0.939534</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.961704</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.946347</td>\n",
       "      <td>0.962548</td>\n",
       "      <td>0.957285</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>0.962548</td>\n",
       "      <td>0.957285</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.954448</td>\n",
       "      <td>0.962548</td>\n",
       "      <td>0.957285</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.961704</td>\n",
       "      <td>0.955707</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.950697</td>\n",
       "      <td>0.957017</td>\n",
       "      <td>0.946448</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.955997</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.950739</td>\n",
       "      <td>0.966276</td>\n",
       "      <td>0.966276</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.942296</td>\n",
       "      <td>0.961584</td>\n",
       "      <td>0.961584</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.938451</td>\n",
       "      <td>0.946606</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.941418</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>0.961013</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.938260</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>0.961013</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.926031</td>\n",
       "      <td>0.966890</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "2                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "8                 8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "9                 9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "10               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "11               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "12               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "       nb_f1     lr_f1    svm_f1  svm_f1_round  \n",
       "0   0.939534  0.953497  0.961704         0.962  \n",
       "1   0.946347  0.962548  0.957285         0.957  \n",
       "2   0.956668  0.962548  0.957285         0.957  \n",
       "3   0.954448  0.962548  0.957285         0.957  \n",
       "4   0.950697  0.961704  0.955707         0.956  \n",
       "5   0.950697  0.957017  0.946448         0.946  \n",
       "6   0.954976  0.955997  0.955883         0.956  \n",
       "7   0.950739  0.966276  0.966276         0.966  \n",
       "8   0.942296  0.961584  0.961584         0.962  \n",
       "9   0.938451  0.946606  0.970874         0.971  \n",
       "10  0.941418  0.970793  0.961013         0.961  \n",
       "11  0.938260  0.970793  0.961013         0.961  \n",
       "12  0.926031  0.966890  0.970793         0.971  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_svm['articles'][\"svm_f1_round\"] = np.round(data_dict_svm['articles'][\"svm_f1\"], decimals=3)\n",
    "data_dict_svm['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>nb_f1</th>\n",
       "      <th>lr_f1</th>\n",
       "      <th>svm_f1</th>\n",
       "      <th>svm_f1_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.383668</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.528260</td>\n",
       "      <td>0.475498</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.549317</td>\n",
       "      <td>0.521787</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.549317</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.562435</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.550293</td>\n",
       "      <td>0.525528</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.525528</td>\n",
       "      <td>0.314204</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.536862</td>\n",
       "      <td>0.475498</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.522268</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.509158</td>\n",
       "      <td>0.393385</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.562435</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.585332</td>\n",
       "      <td>0.447188</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.540034</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.530195</td>\n",
       "      <td>0.447188</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.464198</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.455888</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "2                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "8                 8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "9                 9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "10               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "11               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "12               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "13               14  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "14               15  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "15               16  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "       nb_f1     lr_f1    svm_f1  svm_f1_round  \n",
       "0   0.247934  0.383668  0.247934         0.248  \n",
       "1   0.247934  0.528260  0.475498         0.475  \n",
       "2   0.247934  0.549317  0.521787         0.522  \n",
       "3   0.247934  0.549317  0.531469         0.531  \n",
       "4   0.247934  0.562435  0.542781         0.543  \n",
       "5   0.247934  0.550293  0.525528         0.526  \n",
       "6   0.247934  0.525528  0.314204         0.314  \n",
       "7   0.247934  0.536862  0.475498         0.475  \n",
       "8   0.247934  0.522268  0.483896         0.484  \n",
       "9   0.247934  0.509158  0.393385         0.393  \n",
       "10  0.247934  0.562435  0.483896         0.484  \n",
       "11  0.247934  0.585332  0.447188         0.447  \n",
       "12  0.247934  0.540034  0.483896         0.484  \n",
       "13  0.247934  0.530195  0.447188         0.447  \n",
       "14  0.247934  0.542781  0.464198         0.464  \n",
       "15  0.247934  0.470588  0.455888         0.456  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_svm[\"smokers\"][\"svm_f1_round\"] = np.round(data_dict_svm[\"smokers\"][\"svm_f1\"], decimals=3)\n",
    "data_dict_svm[\"smokers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DA performance for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [\"polarity\", \"articles\", \"smokers\"]\n",
    "model_type = {\n",
    "    \"polarity\": [\"distilbert-base-uncased\"],\n",
    "    \"articles\": [\"distilbert-base-uncased\"],\n",
    "    \"smokers\": [\n",
    "        \"distilbert-base-uncased\",\n",
    "        \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "    ],\n",
    "}\n",
    "data_dict_lstm = {}\n",
    "for data_type in data_types:\n",
    "    # Add the test f1 from the logs using re\n",
    "    # (because I mistakenly did not add these to the json!!!!)\n",
    "    with open(os.path.join(cur_dir, \"..\", f\"logs/training_rnn_classif/{data_type}.log\"), \"r\") as f:\n",
    "        text = f.read()\n",
    "        results = re.findall(r\"Here is the test results.*\\n.*\\n.*f1 score.*(0\\.\\d+)\", text)\n",
    "    # Get the aug info\n",
    "    data = []\n",
    "    with open(os.path.join(cur_dir, \"..\", f\"logs/training_rnn_classif/{data_type}.log\"), \"r\") as f:\n",
    "        dict_ = {}\n",
    "        for i, line in enumerate(f):\n",
    "            if \"with augmentation\" in line.lower():\n",
    "                result = re.match(r\".*with augmentation (\\d+)\", line)\n",
    "                dict_[\"augmentation_id\"] = int(result.group(1))\n",
    "            if \"augmentation features\" in line.lower():\n",
    "                result = re.match(r\".*Augmentation features: (.*)\", line)\n",
    "                dict_[\"augmentation_features\"] = ast.literal_eval(result.group(1))\n",
    "                data.append(dict_)\n",
    "                dict_ = {}\n",
    "    data_new = copy.deepcopy(data)\n",
    "    if data_type == \"smokers\":\n",
    "        data_new = [copy.deepcopy(x) for x in data_new for _ in range(2)]\n",
    "        for i, dict_ in enumerate(data_new):\n",
    "            if (i % 2) == 0:\n",
    "                data_new[i][\"model_type\"] = \"distilbert-base-uncased\"\n",
    "                data_new[i][\"f1\"] = results[i]\n",
    "            else:\n",
    "                data_new[i][\"model_type\"] = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "                data_new[i][\"f1\"] = results[i]\n",
    "    else:\n",
    "        for i, dict_ in enumerate(data_new):\n",
    "            data_new[i][\"model_type\"] = \"distilbert-base-uncased\"\n",
    "            data_new[i][\"f1\"] = results[i]\n",
    "    data = pd.DataFrame(data_new)\n",
    "    data_dict_lstm[data_type] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>model_type</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "2                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "8                 8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "9                 9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "10               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "11               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "12               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "                 model_type     f1  \n",
       "0   distilbert-base-uncased  0.771  \n",
       "1   distilbert-base-uncased   0.73  \n",
       "2   distilbert-base-uncased  0.722  \n",
       "3   distilbert-base-uncased   0.73  \n",
       "4   distilbert-base-uncased  0.749  \n",
       "5   distilbert-base-uncased  0.732  \n",
       "6   distilbert-base-uncased  0.745  \n",
       "7   distilbert-base-uncased  0.770  \n",
       "8   distilbert-base-uncased  0.772  \n",
       "9   distilbert-base-uncased  0.759  \n",
       "10  distilbert-base-uncased  0.737  \n",
       "11  distilbert-base-uncased  0.772  \n",
       "12  distilbert-base-uncased  0.728  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_lstm[\"polarity\"]\n",
    "# NOTE: The values for augmentation_id = {1, 2, 3} are recalculated because they were initially on\n",
    "# the unidirectional LSTM model\n",
    "data_dict_lstm[\"polarity\"].loc[data_dict_lstm[\"polarity\"][\"augmentation_id\"] == 1, \"f1\"] = 0.730\n",
    "data_dict_lstm[\"polarity\"].loc[data_dict_lstm[\"polarity\"][\"augmentation_id\"] == 2,\"f1\"] = 0.722\n",
    "data_dict_lstm[\"polarity\"].loc[data_dict_lstm[\"polarity\"][\"augmentation_id\"] == 3, \"f1\"] = 0.730\n",
    "data_dict_lstm[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>model_type</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "2                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "8                 8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "9                 9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "10               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "11               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "12               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "                 model_type     f1  \n",
       "0   distilbert-base-uncased  0.888  \n",
       "1   distilbert-base-uncased  0.892  \n",
       "2   distilbert-base-uncased  0.906  \n",
       "3   distilbert-base-uncased  0.930  \n",
       "4   distilbert-base-uncased  0.924  \n",
       "5   distilbert-base-uncased  0.937  \n",
       "6   distilbert-base-uncased  0.926  \n",
       "7   distilbert-base-uncased  0.914  \n",
       "8   distilbert-base-uncased  0.928  \n",
       "9   distilbert-base-uncased  0.914  \n",
       "10  distilbert-base-uncased  0.924  \n",
       "11  distilbert-base-uncased  0.924  \n",
       "12  distilbert-base-uncased  0.937  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_lstm[\"articles\"]\n",
    "# NOTE: The values for augmentation_id = {5, 6, 9, 11, 12} are recalculated because they were initially on\n",
    "# the unidirectional LSTM model\n",
    "data_dict_lstm[\"articles\"].loc[data_dict_lstm[\"articles\"][\"augmentation_id\"] == 5, \"f1\"] = 0.937\n",
    "data_dict_lstm[\"articles\"].loc[data_dict_lstm[\"articles\"][\"augmentation_id\"] == 6, \"f1\"] = 0.926\n",
    "data_dict_lstm[\"articles\"].loc[data_dict_lstm[\"articles\"][\"augmentation_id\"] == 9, \"f1\"] = 0.914\n",
    "data_dict_lstm[\"articles\"].loc[data_dict_lstm[\"articles\"][\"augmentation_id\"] == 11, \"f1\"] = 0.924\n",
    "data_dict_lstm[\"articles\"].loc[data_dict_lstm[\"articles\"][\"augmentation_id\"] == 12, \"f1\"] = 0.924\n",
    "data_dict_lstm[\"articles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augmentation_id</th>\n",
       "      <th>augmentation_features</th>\n",
       "      <th>model_type</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>{'num_samples': 0, 'augmentation_type': 'none'}</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'rando...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'synon...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16</td>\n",
       "      <td>{'num_samples': 5, 'augmentation_type': 'conte...</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    augmentation_id                              augmentation_features  \\\n",
       "0                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "1                 0    {'num_samples': 0, 'augmentation_type': 'none'}   \n",
       "2                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "3                 1  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "4                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "5                 2  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "6                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "7                 3  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "8                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "9                 4  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "10                5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "11                5  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "12                6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "13                6  {'num_samples': 5, 'augmentation_type': 'rando...   \n",
       "14                7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "15                7  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "16                8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "17                8  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "18                9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "19                9  {'num_samples': 5, 'augmentation_type': 'synon...   \n",
       "20               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "21               11  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "22               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "23               12  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "24               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "25               13  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "26               14  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "27               14  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "28               15  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "29               15  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "30               16  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "31               16  {'num_samples': 5, 'augmentation_type': 'conte...   \n",
       "\n",
       "                                           model_type     f1  \n",
       "0                             distilbert-base-uncased  0.365  \n",
       "1   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.345  \n",
       "2                             distilbert-base-uncased  0.350  \n",
       "3   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.361  \n",
       "4                             distilbert-base-uncased  0.284  \n",
       "5   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.444  \n",
       "6                             distilbert-base-uncased  0.425  \n",
       "7   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.386  \n",
       "8                             distilbert-base-uncased  0.354  \n",
       "9   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.376  \n",
       "10                            distilbert-base-uncased  0.368  \n",
       "11  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.381  \n",
       "12                            distilbert-base-uncased  0.408  \n",
       "13  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.358  \n",
       "14                            distilbert-base-uncased  0.366  \n",
       "15  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.325  \n",
       "16                            distilbert-base-uncased  0.385  \n",
       "17  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.505  \n",
       "18                            distilbert-base-uncased  0.331  \n",
       "19  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.438  \n",
       "20                            distilbert-base-uncased  0.329  \n",
       "21  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.386  \n",
       "22                            distilbert-base-uncased  0.391  \n",
       "23  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.357  \n",
       "24                            distilbert-base-uncased  0.424  \n",
       "25  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.423  \n",
       "26                            distilbert-base-uncased  0.416  \n",
       "27  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.432  \n",
       "28                            distilbert-base-uncased  0.382  \n",
       "29  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.392  \n",
       "30                            distilbert-base-uncased  0.422  \n",
       "31  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...  0.378  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_lstm[\"smokers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average improvement of standard DA technique for each classifier $\\times$ task pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity [0.789 0.793 0.783 0.79 ]\n",
      "articles [0.957 0.956 0.971 0.971]\n",
      "smokers [0.531 0.543 0.484 0.484 0.464]\n",
      "[  2.70182292   0.18191268 102.09677419]\n",
      "[2 0 1 0 1]\n",
      "[5, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "# For the svm models\n",
    "average_delta_f1 = []\n",
    "best_p_count = [0, 0, 0]\n",
    "for data_type in [\"polarity\", \"articles\", \"smokers\"]:\n",
    "    data_dict_svm[data_type][\"augmentation_type\"] = data_dict_svm[data_type][\"augmentation_features\"].apply(lambda x: x[\"augmentation_type\"])\n",
    "    # Take the max because that's what you would pick for the DA\n",
    "    # Also calculate what's the best p_count\n",
    "    f1_0 = data_dict_svm[data_type].loc[0, \"svm_f1_round\"]\n",
    "    f1_list = data_dict_svm[data_type].loc[1:, \"svm_f1_round\"].values\n",
    "    best_p_list = np.array([f1_list[i:i+3].argmax() for i in range(0, len(f1_list), 3)])\n",
    "    best_p_count = [x + (best_p_list == i).sum() for i, x in enumerate(best_p_count)]\n",
    "    f1_list = np.array([f1_list[i:i+3].max() for i in range(0, len(f1_list), 3)])\n",
    "    print(data_type, f1_list)\n",
    "    average_delta_f1.append(((f1_list - f1_0)/f1_0).mean())\n",
    "print(np.array(average_delta_f1)*100)\n",
    "print(best_p_list)\n",
    "print(best_p_count)\n",
    "# print(f1_0, f1_list)\n",
    "# data_dict_svm[\"smokers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity distilbert-base-uncased [0.73  0.749 0.772 0.772]\n",
      "articles distilbert-base-uncased [0.93  0.937 0.928 0.937]\n",
      "smokers distilbert-base-uncased [0.425 0.408 0.385 0.424 0.422]\n",
      "smokers microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext [0.444 0.386 0.505 0.438 0.432 0.378]\n",
      "[-1.97795071  5.06756757 13.09589041 24.7826087 ]\n",
      "[5, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "# For the svm models\n",
    "average_delta_f1 = []\n",
    "best_p_count = [0, 0, 0]\n",
    "model_type = {\n",
    "    \"polarity\": [\"distilbert-base-uncased\"],\n",
    "    \"articles\": [\"distilbert-base-uncased\"],\n",
    "    \"smokers\": [\n",
    "        \"distilbert-base-uncased\",\n",
    "        \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "    ],\n",
    "}\n",
    "for data_type in [\"polarity\", \"articles\", \"smokers\"]:\n",
    "    for model in model_type[data_type]:\n",
    "        data_ = data_dict_lstm[data_type]\n",
    "        data_ = data_[data_[\"model_type\"] == model]\n",
    "        # data_[\"augmentation_type\"] = data_[\"augmentation_features\"].apply(lambda x: x[\"augmentation_type\"])\n",
    "        # Take the max because that's what you would pick for the DA\n",
    "        f1_0 = float(data_[\"f1\"].values[0])\n",
    "        f1_list = data_.loc[1:, \"f1\"].values.astype(float)\n",
    "        best_p_list = np.array([f1_list[i:i+3].argmax() for i in range(0, len(f1_list), 3)])\n",
    "        best_p_count = [x + (best_p_list == i).sum() for i, x in enumerate(best_p_count)]\n",
    "        f1_list = np.array([f1_list[i:i+3].max() for i in range(0, len(f1_list), 3)])\n",
    "        print(data_type, model, f1_list)\n",
    "        average_delta_f1.append(((f1_list - f1_0)/f1_0).mean())\n",
    "print(np.array(average_delta_f1)*100)\n",
    "print(best_p_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing our model to the BERT augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    \"random_mask\": [0.772, 0.945, 0.424, 0.422, 0.423, 0.432], \n",
    "    \"our_model\": [0.783, 0.95, 0.451, 0.451, 0.537, 0.537]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_increase = (((df[\"our_model\"] - df[\"random_mask\"])/df[\"random_mask\"])*100).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6199812214969205"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_increase[2:4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.627955082742325"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_increase[4:].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76563bcb032bc92047f8af45874c31363a00cf84e256bade488e530cde1f4b4b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
