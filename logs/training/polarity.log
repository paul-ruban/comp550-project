2021-12-07 20:26:59,263 [INFO] Starting polarity training
2021-12-07 20:26:59,275 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 20:26:59,275 [INFO] Starting training for polarity with augmentation 0
2021-12-07 20:26:59,276 [INFO] Augmentation features: {'num_samples': 0, 'augmentation_type': 'none'}
2021-12-07 20:26:59,378 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 20:27:32,709 [DEBUG] Results of the grid search for the model:
2021-12-07 20:27:32,710 [DEBUG] Best estimator:
2021-12-07 20:27:32,717 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2b87489e20>)),
                ('model', MultinomialNB())])
2021-12-07 20:27:32,719 [DEBUG] Best parameters:
2021-12-07 20:27:32,719 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2b883dadf0>}
2021-12-07 20:27:32,720 [DEBUG] Best (f1) score:
2021-12-07 20:27:32,720 [DEBUG] 0.7780835741479748
2021-12-07 20:27:35,527 [DEBUG] Val set results of the best classifier:
2021-12-07 20:27:35,651 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.82      0.79       538
           1       0.80      0.74      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 20:27:35,667 [DEBUG] [[441  97]
 [139 389]]
2021-12-07 20:27:35,715 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 20:28:07,184 [DEBUG] Results of the grid search for the model:
2021-12-07 20:28:07,185 [DEBUG] Best estimator:
2021-12-07 20:28:07,190 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7f2b8747b7c0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 20:28:07,190 [DEBUG] Best parameters:
2021-12-07 20:28:07,191 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2b8747bb50>}
2021-12-07 20:28:07,192 [DEBUG] Best (f1) score:
2021-12-07 20:28:07,192 [DEBUG] 0.7663570898547357
2021-12-07 20:28:12,396 [DEBUG] Val set results of the best classifier:
2021-12-07 20:28:12,581 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.78      0.77       538
           1       0.77      0.76      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 20:28:12,604 [DEBUG] [[417 121]
 [128 400]]
2021-12-07 20:28:12,615 [DEBUG] ---------------Starting training for rf---------------
2021-12-07 20:34:38,023 [DEBUG] Results of the grid search for the model:
2021-12-07 20:34:38,024 [DEBUG] Best estimator:
2021-12-07 20:34:38,028 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f2b87489e20>)),
                ('model',
                 RandomForestClassifier(min_samples_split=5, n_estimators=500,
                                        n_jobs=-1))])
2021-12-07 20:34:38,029 [DEBUG] Best parameters:
2021-12-07 20:34:38,029 [DEBUG] {'model__min_samples_split': 5, 'model__n_estimators': 500, 'model__n_jobs': -1, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2b86c0fb80>}
2021-12-07 20:34:38,030 [DEBUG] Best (f1) score:
2021-12-07 20:34:38,031 [DEBUG] 0.7345213423622019
2021-12-07 20:35:08,491 [DEBUG] Val set results of the best classifier:
2021-12-07 20:35:08,673 [DEBUG]               precision    recall  f1-score   support

           0       0.74      0.73      0.74       538
           1       0.73      0.74      0.73       528

    accuracy                           0.74      1066
   macro avg       0.74      0.74      0.74      1066
weighted avg       0.74      0.74      0.74      1066

2021-12-07 20:35:08,696 [DEBUG] [[394 144]
 [138 390]]
2021-12-07 20:35:09,211 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 20:35:09,212 [INFO] Starting training for polarity with augmentation 1
2021-12-07 20:35:09,213 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.25}
2021-12-07 20:35:09,738 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 20:37:32,787 [DEBUG] Results of the grid search for the model:
2021-12-07 20:37:32,788 [DEBUG] Best estimator:
2021-12-07 20:37:32,791 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2b8797d190>)),
                ('model', MultinomialNB())])
2021-12-07 20:37:32,791 [DEBUG] Best parameters:
2021-12-07 20:37:32,792 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2b8747b8b0>}
2021-12-07 20:37:32,793 [DEBUG] Best (f1) score:
2021-12-07 20:37:32,793 [DEBUG] 0.779223125564589
2021-12-07 20:37:47,351 [DEBUG] Val set results of the best classifier:
2021-12-07 20:37:47,471 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.81      0.79       538
           1       0.79      0.75      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 20:37:47,487 [DEBUG] [[436 102]
 [133 395]]
2021-12-07 20:37:47,610 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 20:40:15,920 [DEBUG] Results of the grid search for the model:
2021-12-07 20:40:15,921 [DEBUG] Best estimator:
2021-12-07 20:40:15,925 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f2ba88b3d00>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 20:40:15,926 [DEBUG] Best parameters:
2021-12-07 20:40:15,927 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2b8760b280>}
2021-12-07 20:40:15,928 [DEBUG] Best (f1) score:
2021-12-07 20:40:15,928 [DEBUG] 0.7795262423706364
2021-12-07 20:40:38,686 [DEBUG] Val set results of the best classifier:
2021-12-07 20:40:38,867 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.76      0.78       538
           1       0.77      0.80      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 20:40:38,889 [DEBUG] [[410 128]
 [107 421]]
2021-12-07 20:40:38,998 [DEBUG] ---------------Starting training for rf---------------
2021-12-07 21:35:53,689 [INFO] Starting polarity training
2021-12-07 21:35:53,701 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:35:53,702 [INFO] Starting training for polarity with augmentation 0
2021-12-07 21:35:53,702 [INFO] Augmentation features: {'num_samples': 0, 'augmentation_type': 'none'}
2021-12-07 21:35:53,805 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 21:36:26,414 [DEBUG] Results of the grid search for the model:
2021-12-07 21:36:26,415 [DEBUG] Best estimator:
2021-12-07 21:36:26,422 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2351538850>)),
                ('model', MultinomialNB())])
2021-12-07 21:36:26,424 [DEBUG] Best parameters:
2021-12-07 21:36:26,424 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2352488dc0>}
2021-12-07 21:36:26,425 [DEBUG] Best (f1) score:
2021-12-07 21:36:26,426 [DEBUG] 0.7780835741479748
2021-12-07 21:36:29,182 [DEBUG] Val set results of the best classifier:
2021-12-07 21:36:29,305 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.82      0.79       538
           1       0.80      0.74      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:36:29,321 [DEBUG] [[441  97]
 [139 389]]
2021-12-07 21:36:29,366 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 21:37:00,231 [DEBUG] Results of the grid search for the model:
2021-12-07 21:37:00,232 [DEBUG] Best estimator:
2021-12-07 21:37:00,236 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7f2351530f40>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 21:37:00,237 [DEBUG] Best parameters:
2021-12-07 21:37:00,237 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2351517a00>}
2021-12-07 21:37:00,238 [DEBUG] Best (f1) score:
2021-12-07 21:37:00,239 [DEBUG] 0.7663570898547357
2021-12-07 21:37:05,477 [DEBUG] Val set results of the best classifier:
2021-12-07 21:37:05,660 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.78      0.77       538
           1       0.77      0.76      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 21:37:05,682 [DEBUG] [[417 121]
 [128 400]]
2021-12-07 21:37:05,694 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:37:05,695 [INFO] Starting training for polarity with augmentation 1
2021-12-07 21:37:05,695 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.25}
2021-12-07 21:37:06,256 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 21:39:26,272 [DEBUG] Results of the grid search for the model:
2021-12-07 21:39:26,273 [DEBUG] Best estimator:
2021-12-07 21:39:26,276 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2351538e80>)),
                ('model', MultinomialNB())])
2021-12-07 21:39:26,277 [DEBUG] Best parameters:
2021-12-07 21:39:26,278 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2351517ee0>}
2021-12-07 21:39:26,279 [DEBUG] Best (f1) score:
2021-12-07 21:39:26,280 [DEBUG] 0.779223125564589
2021-12-07 21:39:40,915 [DEBUG] Val set results of the best classifier:
2021-12-07 21:39:41,042 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.81      0.79       538
           1       0.79      0.75      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:39:41,058 [DEBUG] [[436 102]
 [133 395]]
2021-12-07 21:39:41,182 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 21:42:10,545 [DEBUG] Results of the grid search for the model:
2021-12-07 21:42:10,546 [DEBUG] Best estimator:
2021-12-07 21:42:10,550 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f23524a2550>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 21:42:10,551 [DEBUG] Best parameters:
2021-12-07 21:42:10,551 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2351538370>}
2021-12-07 21:42:10,552 [DEBUG] Best (f1) score:
2021-12-07 21:42:10,552 [DEBUG] 0.7795262423706364
2021-12-07 21:42:33,261 [DEBUG] Val set results of the best classifier:
2021-12-07 21:42:33,443 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.76      0.78       538
           1       0.77      0.80      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:42:33,467 [DEBUG] [[410 128]
 [107 421]]
2021-12-07 21:42:33,580 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:42:33,581 [INFO] Starting training for polarity with augmentation 2
2021-12-07 21:42:33,581 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.5}
2021-12-07 21:42:34,096 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 21:45:12,592 [DEBUG] Results of the grid search for the model:
2021-12-07 21:45:12,593 [DEBUG] Best estimator:
2021-12-07 21:45:12,597 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f234aaa60a0>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 21:45:12,598 [DEBUG] Best parameters:
2021-12-07 21:45:12,598 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2351517700>}
2021-12-07 21:45:12,599 [DEBUG] Best (f1) score:
2021-12-07 21:45:12,600 [DEBUG] 0.7783861874559548
2021-12-07 21:45:42,696 [DEBUG] Val set results of the best classifier:
2021-12-07 21:45:42,816 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.80      0.79       538
           1       0.79      0.75      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:45:42,831 [DEBUG] [[432 106]
 [130 398]]
2021-12-07 21:45:42,956 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 21:48:32,533 [DEBUG] Results of the grid search for the model:
2021-12-07 21:48:32,534 [DEBUG] Best estimator:
2021-12-07 21:48:32,538 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f2351530970>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 21:48:32,539 [DEBUG] Best parameters:
2021-12-07 21:48:32,539 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f234aaa6eb0>}
2021-12-07 21:48:32,540 [DEBUG] Best (f1) score:
2021-12-07 21:48:32,541 [DEBUG] 0.7757924407588985
2021-12-07 21:49:08,035 [DEBUG] Val set results of the best classifier:
2021-12-07 21:49:08,217 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.77      0.78       538
           1       0.77      0.78      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:49:08,240 [DEBUG] [[416 122]
 [117 411]]
2021-12-07 21:49:08,375 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:49:08,376 [INFO] Starting training for polarity with augmentation 3
2021-12-07 21:49:08,376 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.75}
2021-12-07 21:49:09,029 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 21:51:37,994 [DEBUG] Results of the grid search for the model:
2021-12-07 21:51:37,995 [DEBUG] Best estimator:
2021-12-07 21:51:37,998 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f23515389a0>)),
                ('model', MultinomialNB())])
2021-12-07 21:51:37,999 [DEBUG] Best parameters:
2021-12-07 21:51:38,000 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2351517e20>}
2021-12-07 21:51:38,000 [DEBUG] Best (f1) score:
2021-12-07 21:51:38,001 [DEBUG] 0.7794082035738847
2021-12-07 21:51:57,064 [DEBUG] Val set results of the best classifier:
2021-12-07 21:51:57,182 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.80      0.78       538
           1       0.79      0.76      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:51:57,197 [DEBUG] [[429 109]
 [126 402]]
2021-12-07 21:51:57,324 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 21:54:25,985 [DEBUG] Results of the grid search for the model:
2021-12-07 21:54:25,986 [DEBUG] Best estimator:
2021-12-07 21:54:25,990 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.WordTokenizer object at 0x7f234aaa6b20>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 21:54:25,991 [DEBUG] Best parameters:
2021-12-07 21:54:25,992 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2351538e50>}
2021-12-07 21:54:25,992 [DEBUG] Best (f1) score:
2021-12-07 21:54:25,993 [DEBUG] 0.776707163803938
2021-12-07 21:54:39,732 [DEBUG] Val set results of the best classifier:
2021-12-07 21:54:39,912 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.78      0.78       538
           1       0.78      0.77      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:54:39,935 [DEBUG] [[420 118]
 [120 408]]
2021-12-07 21:54:41,157 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:54:41,158 [INFO] Starting training for polarity with augmentation 4
2021-12-07 21:54:41,159 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.25}
2021-12-07 21:54:41,643 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 21:56:45,591 [DEBUG] Results of the grid search for the model:
2021-12-07 21:56:45,592 [DEBUG] Best estimator:
2021-12-07 21:56:45,595 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7f2352488fa0>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 21:56:45,596 [DEBUG] Best parameters:
2021-12-07 21:56:45,596 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f235154af40>}
2021-12-07 21:56:45,597 [DEBUG] Best (f1) score:
2021-12-07 21:56:45,598 [DEBUG] 0.7710996902281047
2021-12-07 21:57:07,775 [DEBUG] Val set results of the best classifier:
2021-12-07 21:57:07,895 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.77      0.77       538
           1       0.77      0.77      0.77       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 21:57:07,910 [DEBUG] [[414 124]
 [120 408]]
2021-12-07 21:57:07,922 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 21:59:06,227 [DEBUG] Results of the grid search for the model:
2021-12-07 21:59:06,228 [DEBUG] Best estimator:
2021-12-07 21:59:06,232 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f23515176a0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 21:59:06,233 [DEBUG] Best parameters:
2021-12-07 21:59:06,233 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f23515305e0>}
2021-12-07 21:59:06,234 [DEBUG] Best (f1) score:
2021-12-07 21:59:06,235 [DEBUG] 0.7785484915917862
2021-12-07 21:59:19,882 [DEBUG] Val set results of the best classifier:
2021-12-07 21:59:20,060 [DEBUG]               precision    recall  f1-score   support

           0       0.80      0.75      0.77       538
           1       0.76      0.80      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 21:59:20,083 [DEBUG] [[406 132]
 [104 424]]
2021-12-07 21:59:20,163 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 21:59:20,163 [INFO] Starting training for polarity with augmentation 5
2021-12-07 21:59:20,164 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.5}
2021-12-07 21:59:20,643 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:01:08,059 [DEBUG] Results of the grid search for the model:
2021-12-07 22:01:08,060 [DEBUG] Best estimator:
2021-12-07 22:01:08,063 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f234aaa6d00>)),
                ('model', MultinomialNB())])
2021-12-07 22:01:08,064 [DEBUG] Best parameters:
2021-12-07 22:01:08,065 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2352488b20>}
2021-12-07 22:01:08,065 [DEBUG] Best (f1) score:
2021-12-07 22:01:08,066 [DEBUG] 0.763268931823229
2021-12-07 22:01:19,670 [DEBUG] Val set results of the best classifier:
2021-12-07 22:01:19,788 [DEBUG]               precision    recall  f1-score   support

           0       0.75      0.79      0.77       538
           1       0.78      0.73      0.75       528

    accuracy                           0.76      1066
   macro avg       0.76      0.76      0.76      1066
weighted avg       0.76      0.76      0.76      1066

2021-12-07 22:01:19,803 [DEBUG] [[427 111]
 [141 387]]
2021-12-07 22:01:19,895 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:03:23,476 [DEBUG] Results of the grid search for the model:
2021-12-07 22:03:23,477 [DEBUG] Best estimator:
2021-12-07 22:03:23,481 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f2341f46790>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:03:23,482 [DEBUG] Best parameters:
2021-12-07 22:03:23,483 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2351530cd0>}
2021-12-07 22:03:23,484 [DEBUG] Best (f1) score:
2021-12-07 22:03:23,484 [DEBUG] 0.7654709940861729
2021-12-07 22:03:47,601 [DEBUG] Val set results of the best classifier:
2021-12-07 22:03:47,778 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.76      0.77       538
           1       0.76      0.77      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:03:47,801 [DEBUG] [[411 127]
 [123 405]]
2021-12-07 22:03:47,883 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:03:47,883 [INFO] Starting training for polarity with augmentation 6
2021-12-07 22:03:47,884 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.75}
2021-12-07 22:03:48,504 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:05:35,422 [DEBUG] Results of the grid search for the model:
2021-12-07 22:05:35,423 [DEBUG] Best estimator:
2021-12-07 22:05:35,427 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f2341f46460>)),
                ('model', MultinomialNB())])
2021-12-07 22:05:35,428 [DEBUG] Best parameters:
2021-12-07 22:05:35,429 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2352488a30>}
2021-12-07 22:05:35,430 [DEBUG] Best (f1) score:
2021-12-07 22:05:35,430 [DEBUG] 0.765465214927149
2021-12-07 22:05:49,453 [DEBUG] Val set results of the best classifier:
2021-12-07 22:05:49,578 [DEBUG]               precision    recall  f1-score   support

           0       0.77      0.77      0.77       538
           1       0.76      0.77      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:05:49,594 [DEBUG] [[412 126]
 [124 404]]
2021-12-07 22:05:49,681 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:07:50,975 [DEBUG] Results of the grid search for the model:
2021-12-07 22:07:50,976 [DEBUG] Best estimator:
2021-12-07 22:07:50,980 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f2351530100>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:07:50,981 [DEBUG] Best parameters:
2021-12-07 22:07:50,981 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2341f460a0>}
2021-12-07 22:07:50,982 [DEBUG] Best (f1) score:
2021-12-07 22:07:50,983 [DEBUG] 0.767325111862927
2021-12-07 22:08:15,489 [DEBUG] Val set results of the best classifier:
2021-12-07 22:08:15,668 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.75      0.76       538
           1       0.75      0.79      0.77       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:08:15,690 [DEBUG] [[403 135]
 [113 415]]
2021-12-07 22:08:15,767 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:08:15,768 [INFO] Starting training for polarity with augmentation 7
2021-12-07 22:08:15,769 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.25, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-07 22:08:16,255 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:10:28,411 [DEBUG] Results of the grid search for the model:
2021-12-07 22:10:28,412 [DEBUG] Best estimator:
2021-12-07 22:10:28,416 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f234aaa6610>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 22:10:28,416 [DEBUG] Best parameters:
2021-12-07 22:10:28,417 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2352488dc0>}
2021-12-07 22:10:28,418 [DEBUG] Best (f1) score:
2021-12-07 22:10:28,418 [DEBUG] 0.7800418322969317
2021-12-07 22:10:45,190 [DEBUG] Val set results of the best classifier:
2021-12-07 22:10:45,308 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.82      0.79       538
           1       0.80      0.74      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:10:45,323 [DEBUG] [[440  98]
 [136 392]]
2021-12-07 22:10:45,371 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:13:05,322 [DEBUG] Results of the grid search for the model:
2021-12-07 22:13:05,323 [DEBUG] Best estimator:
2021-12-07 22:13:05,327 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f2351517190>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:13:05,328 [DEBUG] Best parameters:
2021-12-07 22:13:05,329 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2341f46730>}
2021-12-07 22:13:05,330 [DEBUG] Best (f1) score:
2021-12-07 22:13:05,331 [DEBUG] 0.7804847140820529
2021-12-07 22:13:21,800 [DEBUG] Val set results of the best classifier:
2021-12-07 22:13:21,984 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.78      0.78       538
           1       0.78      0.78      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:13:22,007 [DEBUG] [[418 120]
 [114 414]]
2021-12-07 22:13:22,020 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:13:22,021 [INFO] Starting training for polarity with augmentation 8
2021-12-07 22:13:22,022 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.5, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-07 22:13:22,648 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:15:35,038 [DEBUG] Results of the grid search for the model:
2021-12-07 22:15:35,039 [DEBUG] Best estimator:
2021-12-07 22:15:35,042 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f234aaa6640>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 22:15:35,043 [DEBUG] Best parameters:
2021-12-07 22:15:35,044 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f2352488ac0>}
2021-12-07 22:15:35,045 [DEBUG] Best (f1) score:
2021-12-07 22:15:35,045 [DEBUG] 0.7800418322969317
2021-12-07 22:15:52,005 [DEBUG] Val set results of the best classifier:
2021-12-07 22:15:52,119 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.82      0.79       538
           1       0.80      0.74      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:15:52,135 [DEBUG] [[440  98]
 [136 392]]
2021-12-07 22:15:52,179 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:18:14,103 [DEBUG] Results of the grid search for the model:
2021-12-07 22:18:14,104 [DEBUG] Best estimator:
2021-12-07 22:18:14,107 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f2351517c10>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:18:14,108 [DEBUG] Best parameters:
2021-12-07 22:18:14,108 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f234aaa6280>}
2021-12-07 22:18:14,109 [DEBUG] Best (f1) score:
2021-12-07 22:18:14,110 [DEBUG] 0.7804847140820529
2021-12-07 22:18:30,425 [DEBUG] Val set results of the best classifier:
2021-12-07 22:18:30,608 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.78      0.78       538
           1       0.78      0.78      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:18:30,630 [DEBUG] [[418 120]
 [114 414]]
2021-12-07 22:18:30,645 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:18:30,645 [INFO] Starting training for polarity with augmentation 9
2021-12-07 22:18:30,646 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.75, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-07 22:18:31,134 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:20:43,370 [DEBUG] Results of the grid search for the model:
2021-12-07 22:20:43,371 [DEBUG] Best estimator:
2021-12-07 22:20:43,374 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f23515177c0>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 22:20:43,375 [DEBUG] Best parameters:
2021-12-07 22:20:43,376 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f235154afa0>}
2021-12-07 22:20:43,376 [DEBUG] Best (f1) score:
2021-12-07 22:20:43,377 [DEBUG] 0.7800418322969317
2021-12-07 22:21:00,114 [DEBUG] Val set results of the best classifier:
2021-12-07 22:21:00,232 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.82      0.79       538
           1       0.80      0.74      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:21:00,247 [DEBUG] [[440  98]
 [136 392]]
2021-12-07 22:21:00,294 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:23:19,305 [DEBUG] Results of the grid search for the model:
2021-12-07 22:23:19,306 [DEBUG] Best estimator:
2021-12-07 22:23:19,310 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f23515385b0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:23:19,310 [DEBUG] Best parameters:
2021-12-07 22:23:19,311 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f234aaa68b0>}
2021-12-07 22:23:19,311 [DEBUG] Best (f1) score:
2021-12-07 22:23:19,312 [DEBUG] 0.7804847140820529
2021-12-07 22:23:35,481 [DEBUG] Val set results of the best classifier:
2021-12-07 22:23:35,657 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.78      0.78       538
           1       0.78      0.78      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:23:35,679 [DEBUG] [[418 120]
 [114 414]]
2021-12-07 22:23:35,691 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:23:35,691 [INFO] Starting training for polarity with augmentation 10
2021-12-07 22:23:35,692 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'backtranslation'}
2021-12-07 22:23:37,617 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:26:38,067 [DEBUG] Results of the grid search for the model:
2021-12-07 22:26:38,068 [DEBUG] Best estimator:
2021-12-07 22:26:38,071 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2351530a30>)),
                ('model', MultinomialNB())])
2021-12-07 22:26:38,072 [DEBUG] Best parameters:
2021-12-07 22:26:38,072 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2352488af0>}
2021-12-07 22:26:38,073 [DEBUG] Best (f1) score:
2021-12-07 22:26:38,073 [DEBUG] 0.7672366127242952
2021-12-07 22:26:58,624 [DEBUG] Val set results of the best classifier:
2021-12-07 22:26:59,546 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.78      0.77       538
           1       0.77      0.75      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:26:59,655 [DEBUG] [[421 117]
 [131 397]]
2021-12-07 22:26:59,717 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:29:47,602 [DEBUG] Results of the grid search for the model:
2021-12-07 22:29:47,603 [DEBUG] Best estimator:
2021-12-07 22:29:47,606 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2341f46430>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:29:47,607 [DEBUG] Best parameters:
2021-12-07 22:29:47,608 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f2351530fd0>}
2021-12-07 22:29:47,608 [DEBUG] Best (f1) score:
2021-12-07 22:29:47,609 [DEBUG] 0.7767158105215726
2021-12-07 22:30:08,758 [DEBUG] Val set results of the best classifier:
2021-12-07 22:30:10,143 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.78      0.78       538
           1       0.77      0.77      0.77       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:30:10,310 [DEBUG] [[419 119]
 [119 409]]
2021-12-07 22:30:10,368 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:30:10,369 [INFO] Starting training for polarity with augmentation 11
2021-12-07 22:30:10,369 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.25, 'model_path': 'distilbert-base-uncased'}
2021-12-07 22:30:12,154 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:32:43,749 [DEBUG] Results of the grid search for the model:
2021-12-07 22:32:43,750 [DEBUG] Best estimator:
2021-12-07 22:32:43,754 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.StemmerTokenizer object at 0x7f23429aa3a0>)),
                ('model', MultinomialNB())])
2021-12-07 22:32:43,755 [DEBUG] Best parameters:
2021-12-07 22:32:43,755 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2352488d00>}
2021-12-07 22:32:43,756 [DEBUG] Best (f1) score:
2021-12-07 22:32:43,757 [DEBUG] 0.7727783591055304
2021-12-07 22:33:13,637 [DEBUG] Val set results of the best classifier:
2021-12-07 22:33:13,761 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.80      0.78       538
           1       0.78      0.75      0.77       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:33:13,777 [DEBUG] [[428 110]
 [132 396]]
2021-12-07 22:33:13,929 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:35:39,273 [DEBUG] Results of the grid search for the model:
2021-12-07 22:35:39,274 [DEBUG] Best estimator:
2021-12-07 22:35:39,277 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.WordTokenizer object at 0x7f2351517160>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:35:39,278 [DEBUG] Best parameters:
2021-12-07 22:35:39,279 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f23515308b0>}
2021-12-07 22:35:39,279 [DEBUG] Best (f1) score:
2021-12-07 22:35:39,280 [DEBUG] 0.7767323160321734
2021-12-07 22:35:52,064 [DEBUG] Val set results of the best classifier:
2021-12-07 22:35:52,251 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.77      0.78       538
           1       0.77      0.79      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:35:52,275 [DEBUG] [[412 126]
 [112 416]]
2021-12-07 22:35:52,293 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:35:52,294 [INFO] Starting training for polarity with augmentation 12
2021-12-07 22:35:52,295 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.5, 'model_path': 'distilbert-base-uncased'}
2021-12-07 22:35:54,073 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:38:28,247 [DEBUG] Results of the grid search for the model:
2021-12-07 22:38:28,248 [DEBUG] Best estimator:
2021-12-07 22:38:28,251 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7f23429aa4c0>)),
                ('model', MultinomialNB(alpha=10.0))])
2021-12-07 22:38:28,252 [DEBUG] Best parameters:
2021-12-07 22:38:28,252 [DEBUG] {'model__alpha': 10.0, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7f2352488dc0>}
2021-12-07 22:38:28,253 [DEBUG] Best (f1) score:
2021-12-07 22:38:28,254 [DEBUG] 0.7586516446119433
2021-12-07 22:38:55,862 [DEBUG] Val set results of the best classifier:
2021-12-07 22:38:55,987 [DEBUG]               precision    recall  f1-score   support

           0       0.75      0.78      0.77       538
           1       0.77      0.73      0.75       528

    accuracy                           0.76      1066
   macro avg       0.76      0.76      0.76      1066
weighted avg       0.76      0.76      0.76      1066

2021-12-07 22:38:56,004 [DEBUG] [[422 116]
 [141 387]]
2021-12-07 22:38:56,020 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:41:25,161 [DEBUG] Results of the grid search for the model:
2021-12-07 22:41:25,162 [DEBUG] Best estimator:
2021-12-07 22:41:25,166 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.WordTokenizer object at 0x7f2341f460d0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:41:25,166 [DEBUG] Best parameters:
2021-12-07 22:41:25,167 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f23515309d0>}
2021-12-07 22:41:25,168 [DEBUG] Best (f1) score:
2021-12-07 22:41:25,168 [DEBUG] 0.77574033925816
2021-12-07 22:41:38,200 [DEBUG] Val set results of the best classifier:
2021-12-07 22:41:38,383 [DEBUG]               precision    recall  f1-score   support

           0       0.79      0.75      0.77       538
           1       0.76      0.80      0.78       528

    accuracy                           0.78      1066
   macro avg       0.78      0.78      0.78      1066
weighted avg       0.78      0.78      0.78      1066

2021-12-07 22:41:38,406 [DEBUG] [[405 133]
 [106 422]]
2021-12-07 22:41:38,424 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:41:38,425 [INFO] Starting training for polarity with augmentation 13
2021-12-07 22:41:38,425 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.75, 'model_path': 'distilbert-base-uncased'}
2021-12-07 22:41:39,083 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:43:54,296 [DEBUG] Results of the grid search for the model:
2021-12-07 22:43:54,298 [DEBUG] Best estimator:
2021-12-07 22:43:54,301 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7f2351517160>)),
                ('model', MultinomialNB())])
2021-12-07 22:43:54,302 [DEBUG] Best parameters:
2021-12-07 22:43:54,303 [DEBUG] {'model__alpha': 1.0, 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7f235154ab50>}
2021-12-07 22:43:54,303 [DEBUG] Best (f1) score:
2021-12-07 22:43:54,304 [DEBUG] 0.7689957716701903
2021-12-07 22:44:09,219 [DEBUG] Val set results of the best classifier:
2021-12-07 22:44:09,348 [DEBUG]               precision    recall  f1-score   support

           0       0.76      0.79      0.78       538
           1       0.78      0.74      0.76       528

    accuracy                           0.77      1066
   macro avg       0.77      0.77      0.77      1066
weighted avg       0.77      0.77      0.77      1066

2021-12-07 22:44:09,365 [DEBUG] [[427 111]
 [135 393]]
2021-12-07 22:44:09,580 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:46:55,032 [DEBUG] Results of the grid search for the model:
2021-12-07 22:46:55,033 [DEBUG] Best estimator:
2021-12-07 22:46:55,037 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f2351538cd0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:46:55,038 [DEBUG] Best parameters:
2021-12-07 22:46:55,039 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7f23524a22b0>}
2021-12-07 22:46:55,040 [DEBUG] Best (f1) score:
2021-12-07 22:46:55,041 [DEBUG] 0.7635015212981745
2021-12-07 22:47:22,883 [DEBUG] Val set results of the best classifier:
2021-12-07 22:47:23,075 [DEBUG]               precision    recall  f1-score   support

           0       0.78      0.74      0.76       538
           1       0.75      0.79      0.77       528

    accuracy                           0.76      1066
   macro avg       0.76      0.76      0.76      1066
weighted avg       0.76      0.76      0.76      1066

2021-12-07 22:47:23,100 [DEBUG] [[396 142]
 [110 418]]
