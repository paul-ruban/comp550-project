2021-12-07 22:47:29,753 [INFO] Starting articles training
2021-12-07 22:47:29,766 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:47:29,767 [INFO] Starting training for articles with augmentation 0
2021-12-07 22:47:29,768 [INFO] Augmentation features: {'num_samples': 0, 'augmentation_type': 'none'}
2021-12-07 22:47:30,594 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 22:49:30,325 [DEBUG] Results of the grid search for the model:
2021-12-07 22:49:30,327 [DEBUG] Best estimator:
2021-12-07 22:49:30,334 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7ff2ba698af0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-07 22:49:30,335 [DEBUG] Best parameters:
2021-12-07 22:49:30,335 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7ff2bb00aeb0>}
2021-12-07 22:49:30,336 [DEBUG] Best (f1) score:
2021-12-07 22:49:30,336 [DEBUG] 0.9694048788850012
2021-12-07 22:49:50,437 [DEBUG] Val set results of the best classifier:
2021-12-07 22:49:51,379 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.91      0.94        56
           1       1.00      1.00      1.00        36
           2       0.93      0.95      0.94        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.97       222
   macro avg       0.97      0.97      0.97       222
weighted avg       0.97      0.97      0.97       222

2021-12-07 22:49:51,513 [DEBUG] [[51  0  3  0  2]
 [ 0 36  0  0  0]
 [ 2  0 38  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 22:49:51,534 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 22:52:32,594 [DEBUG] Results of the grid search for the model:
2021-12-07 22:52:32,595 [DEBUG] Best estimator:
2021-12-07 22:52:32,599 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7ff2ba6d8310>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 22:52:32,599 [DEBUG] Best parameters:
2021-12-07 22:52:32,600 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7ff2ba698b50>}
2021-12-07 22:52:32,600 [DEBUG] Best (f1) score:
2021-12-07 22:52:32,601 [DEBUG] 0.9682026191746157
2021-12-07 22:52:56,179 [DEBUG] Val set results of the best classifier:
2021-12-07 22:52:58,044 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.95      0.95        56
           1       0.97      1.00      0.99        36
           2       0.95      0.93      0.94        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.97       222
   macro avg       0.97      0.97      0.97       222
weighted avg       0.97      0.97      0.97       222

2021-12-07 22:52:58,274 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 2  0 37  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-07 22:52:58,298 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 22:52:58,298 [INFO] Starting training for articles with augmentation 1
2021-12-07 22:52:58,299 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.25}
2021-12-07 22:53:02,745 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 23:03:05,806 [DEBUG] Results of the grid search for the model:
2021-12-07 23:03:05,807 [DEBUG] Best estimator:
2021-12-07 23:03:05,810 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2d951e610>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-07 23:03:05,811 [DEBUG] Best parameters:
2021-12-07 23:03:05,811 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2bb00af40>}
2021-12-07 23:03:05,812 [DEBUG] Best (f1) score:
2021-12-07 23:03:05,813 [DEBUG] 0.9780128752605817
2021-12-07 23:04:18,327 [DEBUG] Val set results of the best classifier:
2021-12-07 23:04:19,264 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-07 23:04:19,383 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 23:04:19,404 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 23:17:39,567 [DEBUG] Results of the grid search for the model:
2021-12-07 23:17:39,568 [DEBUG] Best estimator:
2021-12-07 23:17:39,572 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6d8400>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 23:17:39,573 [DEBUG] Best parameters:
2021-12-07 23:17:39,574 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951ed00>}
2021-12-07 23:17:39,574 [DEBUG] Best (f1) score:
2021-12-07 23:17:39,575 [DEBUG] 0.9737581747301715
2021-12-07 23:19:14,023 [DEBUG] Val set results of the best classifier:
2021-12-07 23:19:15,891 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.95      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.93      0.94        40
           3       0.98      1.00      0.99        54
           4       0.97      1.00      0.99        36

    accuracy                           0.97       222
   macro avg       0.97      0.97      0.97       222
weighted avg       0.97      0.97      0.97       222

2021-12-07 23:19:16,386 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 2  0 37  1  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 23:19:16,421 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 23:19:16,422 [INFO] Starting training for articles with augmentation 2
2021-12-07 23:19:16,422 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.5}
2021-12-07 23:19:21,063 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 23:29:34,323 [DEBUG] Results of the grid search for the model:
2021-12-07 23:29:34,324 [DEBUG] Best estimator:
2021-12-07 23:29:34,328 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2d951e5b0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-07 23:29:34,330 [DEBUG] Best parameters:
2021-12-07 23:29:34,330 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8be0>}
2021-12-07 23:29:34,331 [DEBUG] Best (f1) score:
2021-12-07 23:29:34,332 [DEBUG] 0.9780128752605817
2021-12-07 23:30:47,640 [DEBUG] Val set results of the best classifier:
2021-12-07 23:30:48,589 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-07 23:30:48,711 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 23:30:48,731 [DEBUG] ---------------Starting training for logistic---------------
2021-12-07 23:44:15,684 [DEBUG] Results of the grid search for the model:
2021-12-07 23:44:15,685 [DEBUG] Best estimator:
2021-12-07 23:44:15,689 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2a829aa60>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-07 23:44:15,690 [DEBUG] Best parameters:
2021-12-07 23:44:15,691 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951ed60>}
2021-12-07 23:44:15,691 [DEBUG] Best (f1) score:
2021-12-07 23:44:15,692 [DEBUG] 0.9737581747301715
2021-12-07 23:45:49,690 [DEBUG] Val set results of the best classifier:
2021-12-07 23:45:51,566 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.95      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.93      0.94        40
           3       0.98      1.00      0.99        54
           4       0.97      1.00      0.99        36

    accuracy                           0.97       222
   macro avg       0.97      0.97      0.97       222
weighted avg       0.97      0.97      0.97       222

2021-12-07 23:45:51,799 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 2  0 37  1  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 23:45:51,821 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-07 23:45:51,821 [INFO] Starting training for articles with augmentation 3
2021-12-07 23:45:51,822 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_swap', 'aug_p': 0.75}
2021-12-07 23:45:56,455 [DEBUG] ---------------Starting training for nb---------------
2021-12-07 23:56:04,600 [DEBUG] Results of the grid search for the model:
2021-12-07 23:56:04,601 [DEBUG] Best estimator:
2021-12-07 23:56:04,604 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2d951ef40>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-07 23:56:04,605 [DEBUG] Best parameters:
2021-12-07 23:56:04,606 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8460>}
2021-12-07 23:56:04,606 [DEBUG] Best (f1) score:
2021-12-07 23:56:04,607 [DEBUG] 0.9780128752605817
2021-12-07 23:57:17,948 [DEBUG] Val set results of the best classifier:
2021-12-07 23:57:18,923 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-07 23:57:19,047 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-07 23:57:19,070 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 00:11:39,449 [DEBUG] Results of the grid search for the model:
2021-12-08 00:11:39,450 [DEBUG] Best estimator:
2021-12-08 00:11:39,455 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2a829a9d0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 00:11:39,456 [DEBUG] Best parameters:
2021-12-08 00:11:39,457 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2d951e580>}
2021-12-08 00:11:39,458 [DEBUG] Best (f1) score:
2021-12-08 00:11:39,459 [DEBUG] 0.9769578614683553
2021-12-08 00:13:43,909 [DEBUG] Val set results of the best classifier:
2021-12-08 00:13:45,757 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 00:13:45,986 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 00:13:46,201 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 00:13:46,202 [INFO] Starting training for articles with augmentation 4
2021-12-08 00:13:46,203 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.25}
2021-12-08 00:13:50,776 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 00:23:59,357 [DEBUG] Results of the grid search for the model:
2021-12-08 00:23:59,358 [DEBUG] Best estimator:
2021-12-08 00:23:59,362 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2d951e550>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 00:23:59,363 [DEBUG] Best parameters:
2021-12-08 00:23:59,364 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8a00>}
2021-12-08 00:23:59,364 [DEBUG] Best (f1) score:
2021-12-08 00:23:59,365 [DEBUG] 0.9780128752605817
2021-12-08 00:25:13,477 [DEBUG] Val set results of the best classifier:
2021-12-08 00:25:14,464 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 00:25:14,591 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 00:25:14,615 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 00:38:58,376 [DEBUG] Results of the grid search for the model:
2021-12-08 00:38:58,377 [DEBUG] Best estimator:
2021-12-08 00:38:58,381 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6a26a0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 00:38:58,382 [DEBUG] Best parameters:
2021-12-08 00:38:58,383 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951ecd0>}
2021-12-08 00:38:58,383 [DEBUG] Best (f1) score:
2021-12-08 00:38:58,384 [DEBUG] 0.9769578614683553
2021-12-08 00:41:12,548 [DEBUG] Val set results of the best classifier:
2021-12-08 00:41:14,500 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 00:41:14,755 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 00:41:14,965 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 00:41:14,966 [INFO] Starting training for articles with augmentation 5
2021-12-08 00:41:14,966 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.5}
2021-12-08 00:41:19,617 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 00:51:08,614 [DEBUG] Results of the grid search for the model:
2021-12-08 00:51:08,615 [DEBUG] Best estimator:
2021-12-08 00:51:08,619 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba698850>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 00:51:08,620 [DEBUG] Best parameters:
2021-12-08 00:51:08,621 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8430>}
2021-12-08 00:51:08,621 [DEBUG] Best (f1) score:
2021-12-08 00:51:08,622 [DEBUG] 0.9780128752605817
2021-12-08 00:52:20,267 [DEBUG] Val set results of the best classifier:
2021-12-08 00:52:21,203 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 00:52:21,322 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 00:52:21,343 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 01:05:54,493 [DEBUG] Results of the grid search for the model:
2021-12-08 01:05:54,495 [DEBUG] Best estimator:
2021-12-08 01:05:54,499 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7ff2a829a940>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 01:05:54,499 [DEBUG] Best parameters:
2021-12-08 01:05:54,500 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951e400>}
2021-12-08 01:05:54,501 [DEBUG] Best (f1) score:
2021-12-08 01:05:54,502 [DEBUG] 0.9769578614683553
2021-12-08 01:08:03,241 [DEBUG] Val set results of the best classifier:
2021-12-08 01:08:05,067 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 01:08:05,300 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 01:08:05,490 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 01:08:05,491 [INFO] Starting training for articles with augmentation 6
2021-12-08 01:08:05,492 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'random_delete', 'aug_p': 0.75}
2021-12-08 01:08:10,090 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 01:18:00,672 [DEBUG] Results of the grid search for the model:
2021-12-08 01:18:00,673 [DEBUG] Best estimator:
2021-12-08 01:18:00,677 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2a829a490>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 01:18:00,678 [DEBUG] Best parameters:
2021-12-08 01:18:00,679 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951e700>}
2021-12-08 01:18:00,680 [DEBUG] Best (f1) score:
2021-12-08 01:18:00,681 [DEBUG] 0.9780128752605817
2021-12-08 01:19:11,739 [DEBUG] Val set results of the best classifier:
2021-12-08 01:19:12,668 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 01:19:12,789 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 01:19:12,813 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 01:33:08,348 [DEBUG] Results of the grid search for the model:
2021-12-08 01:33:08,349 [DEBUG] Best estimator:
2021-12-08 01:33:08,353 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6b00d0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 01:33:08,354 [DEBUG] Best parameters:
2021-12-08 01:33:08,354 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8e50>}
2021-12-08 01:33:08,355 [DEBUG] Best (f1) score:
2021-12-08 01:33:08,356 [DEBUG] 0.9769578614683553
2021-12-08 01:35:18,181 [DEBUG] Val set results of the best classifier:
2021-12-08 01:35:20,056 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 01:35:20,289 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 01:35:20,504 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 01:35:20,505 [INFO] Starting training for articles with augmentation 7
2021-12-08 01:35:20,505 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.25, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-08 01:35:28,305 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 01:45:22,192 [DEBUG] Results of the grid search for the model:
2021-12-08 01:45:22,193 [DEBUG] Best estimator:
2021-12-08 01:45:22,197 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6a22b0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 01:45:22,198 [DEBUG] Best parameters:
2021-12-08 01:45:22,199 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951e9d0>}
2021-12-08 01:45:22,199 [DEBUG] Best (f1) score:
2021-12-08 01:45:22,200 [DEBUG] 0.9780128752605817
2021-12-08 01:46:34,393 [DEBUG] Val set results of the best classifier:
2021-12-08 01:46:35,354 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 01:46:35,479 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 01:46:35,501 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 01:59:45,022 [DEBUG] Results of the grid search for the model:
2021-12-08 01:59:45,023 [DEBUG] Best estimator:
2021-12-08 01:59:45,027 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2ba6b0730>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 01:59:45,028 [DEBUG] Best parameters:
2021-12-08 01:59:45,028 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2d951ea00>}
2021-12-08 01:59:45,029 [DEBUG] Best (f1) score:
2021-12-08 01:59:45,029 [DEBUG] 0.9813220824805959
2021-12-08 02:01:33,094 [DEBUG] Val set results of the best classifier:
2021-12-08 02:01:34,986 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      1.00      0.98        40
           3       1.00      1.00      1.00        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 02:01:35,219 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 40  0  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 02:01:35,366 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 02:01:35,366 [INFO] Starting training for articles with augmentation 8
2021-12-08 02:01:35,367 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.5, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-08 02:01:40,009 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 02:11:40,495 [DEBUG] Results of the grid search for the model:
2021-12-08 02:11:40,497 [DEBUG] Best estimator:
2021-12-08 02:11:40,500 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ab064eb0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 02:11:40,501 [DEBUG] Best parameters:
2021-12-08 02:11:40,502 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951e580>}
2021-12-08 02:11:40,502 [DEBUG] Best (f1) score:
2021-12-08 02:11:40,503 [DEBUG] 0.9780128752605817
2021-12-08 02:12:52,828 [DEBUG] Val set results of the best classifier:
2021-12-08 02:12:53,770 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 02:12:53,961 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 02:12:53,991 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 02:25:59,778 [DEBUG] Results of the grid search for the model:
2021-12-08 02:25:59,780 [DEBUG] Best estimator:
2021-12-08 02:25:59,784 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2ba6b0280>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 02:25:59,785 [DEBUG] Best parameters:
2021-12-08 02:25:59,785 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2ba6a2310>}
2021-12-08 02:25:59,786 [DEBUG] Best (f1) score:
2021-12-08 02:25:59,787 [DEBUG] 0.9813220824805959
2021-12-08 02:27:47,696 [DEBUG] Val set results of the best classifier:
2021-12-08 02:27:49,590 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      1.00      0.98        40
           3       1.00      1.00      1.00        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 02:27:49,825 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 40  0  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 02:27:50,004 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 02:27:50,004 [INFO] Starting training for articles with augmentation 9
2021-12-08 02:27:50,005 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'synonym_wordnet', 'aug_p': 0.75, 'stopwords_regex': '.*[^a-zA-Z].*'}
2021-12-08 02:27:56,086 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 02:38:01,587 [DEBUG] Results of the grid search for the model:
2021-12-08 02:38:01,588 [DEBUG] Best estimator:
2021-12-08 02:38:01,592 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ab064b50>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 02:38:01,593 [DEBUG] Best parameters:
2021-12-08 02:38:01,594 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6e6b50>}
2021-12-08 02:38:01,595 [DEBUG] Best (f1) score:
2021-12-08 02:38:01,596 [DEBUG] 0.9780128752605817
2021-12-08 02:39:13,531 [DEBUG] Val set results of the best classifier:
2021-12-08 02:39:14,488 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.93      0.95        56
           1       1.00      1.00      1.00        36
           2       0.95      0.97      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 02:39:14,610 [DEBUG] [[52  0  2  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 02:39:14,641 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 02:52:21,252 [DEBUG] Results of the grid search for the model:
2021-12-08 02:52:21,253 [DEBUG] Best estimator:
2021-12-08 02:52:21,257 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2a829adf0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 02:52:21,258 [DEBUG] Best parameters:
2021-12-08 02:52:21,258 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2d951ebe0>}
2021-12-08 02:52:21,259 [DEBUG] Best (f1) score:
2021-12-08 02:52:21,259 [DEBUG] 0.9813220824805959
2021-12-08 02:54:08,803 [DEBUG] Val set results of the best classifier:
2021-12-08 02:54:10,696 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      1.00      0.98        40
           3       1.00      1.00      1.00        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 02:54:10,930 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 40  0  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 02:54:11,074 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 02:54:11,074 [INFO] Starting training for articles with augmentation 10
2021-12-08 02:54:11,075 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'backtranslation'}
2021-12-08 02:54:15,718 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 03:00:34,944 [DEBUG] Results of the grid search for the model:
2021-12-08 03:00:34,945 [DEBUG] Best estimator:
2021-12-08 03:00:34,949 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.StemmerTokenizer object at 0x7ff2ab064e50>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 03:00:34,950 [DEBUG] Best parameters:
2021-12-08 03:00:34,950 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.StemmerTokenizer object at 0x7ff2ba6e60d0>}
2021-12-08 03:00:34,951 [DEBUG] Best (f1) score:
2021-12-08 03:00:34,952 [DEBUG] 0.9737273859225078
2021-12-08 03:01:44,646 [DEBUG] Val set results of the best classifier:
2021-12-08 03:01:45,600 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.91      0.94        56
           1       1.00      1.00      1.00        36
           2       0.93      0.97      0.95        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.97       222
   macro avg       0.97      0.98      0.97       222
weighted avg       0.97      0.97      0.97       222

2021-12-08 03:01:45,722 [DEBUG] [[51  0  3  0  2]
 [ 0 36  0  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 03:01:45,747 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 03:10:48,567 [DEBUG] Results of the grid search for the model:
2021-12-08 03:10:48,568 [DEBUG] Best estimator:
2021-12-08 03:10:48,573 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2abeadaf0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 03:10:48,573 [DEBUG] Best parameters:
2021-12-08 03:10:48,574 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2bb00ad30>}
2021-12-08 03:10:48,575 [DEBUG] Best (f1) score:
2021-12-08 03:10:48,575 [DEBUG] 0.9778621785477377
2021-12-08 03:11:54,814 [DEBUG] Val set results of the best classifier:
2021-12-08 03:11:56,704 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.95      0.96        56
           1       1.00      0.97      0.99        36
           2       0.91      0.97      0.94        40
           3       1.00      1.00      1.00        54
           4       1.00      1.00      1.00        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 03:11:56,940 [DEBUG] [[53  0  3  0  0]
 [ 0 35  1  0  0]
 [ 1  0 39  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 03:11:56,970 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 03:11:56,971 [INFO] Starting training for articles with augmentation 11
2021-12-08 03:11:56,971 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.25, 'model_path': 'distilbert-base-uncased'}
2021-12-08 03:12:01,627 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 03:22:13,026 [DEBUG] Results of the grid search for the model:
2021-12-08 03:22:13,027 [DEBUG] Best estimator:
2021-12-08 03:22:13,031 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6b0af0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 03:22:13,032 [DEBUG] Best parameters:
2021-12-08 03:22:13,032 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2d951e400>}
2021-12-08 03:22:13,033 [DEBUG] Best (f1) score:
2021-12-08 03:22:13,034 [DEBUG] 0.9778920682276855
2021-12-08 03:23:26,983 [DEBUG] Val set results of the best classifier:
2021-12-08 03:23:27,945 [DEBUG]               precision    recall  f1-score   support

           0       0.98      0.95      0.96        56
           1       1.00      1.00      1.00        36
           2       0.97      0.95      0.96        40
           3       0.98      1.00      0.99        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 03:23:28,066 [DEBUG] [[53  0  1  0  2]
 [ 0 36  0  0  0]
 [ 1  0 38  1  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 03:23:28,091 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 03:37:29,576 [DEBUG] Results of the grid search for the model:
2021-12-08 03:37:29,577 [DEBUG] Best estimator:
2021-12-08 03:37:29,581 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2abead9a0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 03:37:29,582 [DEBUG] Best parameters:
2021-12-08 03:37:29,582 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2d951e640>}
2021-12-08 03:37:29,583 [DEBUG] Best (f1) score:
2021-12-08 03:37:29,583 [DEBUG] 0.9769578614683553
2021-12-08 03:39:37,031 [DEBUG] Val set results of the best classifier:
2021-12-08 03:39:38,932 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 03:39:39,170 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 03:39:39,387 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 03:39:39,388 [INFO] Starting training for articles with augmentation 12
2021-12-08 03:39:39,388 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.5, 'model_path': 'distilbert-base-uncased'}
2021-12-08 03:39:44,061 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 03:49:49,372 [DEBUG] Results of the grid search for the model:
2021-12-08 03:49:49,373 [DEBUG] Best estimator:
2021-12-08 03:49:49,376 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ab064df0>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 03:49:49,377 [DEBUG] Best parameters:
2021-12-08 03:49:49,378 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2ba6d8ac0>}
2021-12-08 03:49:49,378 [DEBUG] Best (f1) score:
2021-12-08 03:49:49,379 [DEBUG] 0.9779906488767247
2021-12-08 03:51:03,064 [DEBUG] Val set results of the best classifier:
2021-12-08 03:51:04,014 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.95      0.95        56
           1       1.00      1.00      1.00        36
           2       0.97      0.95      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 03:51:04,138 [DEBUG] [[53  0  1  0  2]
 [ 0 36  0  0  0]
 [ 2  0 38  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 03:51:04,166 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 04:05:02,061 [DEBUG] Results of the grid search for the model:
2021-12-08 04:05:02,063 [DEBUG] Best estimator:
2021-12-08 04:05:02,067 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2aba02d60>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 04:05:02,067 [DEBUG] Best parameters:
2021-12-08 04:05:02,068 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2ba6e6160>}
2021-12-08 04:05:02,068 [DEBUG] Best (f1) score:
2021-12-08 04:05:02,069 [DEBUG] 0.9769578614683553
2021-12-08 04:07:10,645 [DEBUG] Val set results of the best classifier:
2021-12-08 04:07:12,548 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 04:07:12,778 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
2021-12-08 04:07:13,011 [INFO] ------------------------------------------------------------------------------------------------------------------------
2021-12-08 04:07:13,012 [INFO] Starting training for articles with augmentation 13
2021-12-08 04:07:13,012 [INFO] Augmentation features: {'num_samples': 5, 'augmentation_type': 'contextual_word_embeddings', 'aug_p': 0.75, 'model_path': 'distilbert-base-uncased'}
2021-12-08 04:07:17,714 [DEBUG] ---------------Starting training for nb---------------
2021-12-08 04:17:30,080 [DEBUG] Results of the grid search for the model:
2021-12-08 04:17:30,081 [DEBUG] Best estimator:
2021-12-08 04:17:30,086 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7ff2ba6a2f70>)),
                ('model', MultinomialNB(alpha=0.1))])
2021-12-08 04:17:30,086 [DEBUG] Best parameters:
2021-12-08 04:17:30,087 [DEBUG] {'model__alpha': 0.1, 'vectorizer__ngram_range': (1, 1), 'vectorizer__tokenizer': <__main__.LemmaTokenizer object at 0x7ff2baff9e80>}
2021-12-08 04:17:30,088 [DEBUG] Best (f1) score:
2021-12-08 04:17:30,088 [DEBUG] 0.9779906488767247
2021-12-08 04:18:44,314 [DEBUG] Val set results of the best classifier:
2021-12-08 04:18:45,309 [DEBUG]               precision    recall  f1-score   support

           0       0.96      0.95      0.95        56
           1       1.00      1.00      1.00        36
           2       0.97      0.95      0.96        40
           3       1.00      1.00      1.00        54
           4       0.95      1.00      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 04:18:45,435 [DEBUG] [[53  0  1  0  2]
 [ 0 36  0  0  0]
 [ 2  0 38  0  0]
 [ 0  0  0 54  0]
 [ 0  0  0  0 36]]
2021-12-08 04:18:45,466 [DEBUG] ---------------Starting training for logistic---------------
2021-12-08 04:32:40,814 [DEBUG] Results of the grid search for the model:
2021-12-08 04:32:40,815 [DEBUG] Best estimator:
2021-12-08 04:32:40,819 [DEBUG] Pipeline(steps=[('vectorizer',
                 TfidfVectorizer(ngram_range=(1, 2),
                                 tokenizer=<__main__.WordTokenizer object at 0x7ff2aba02ee0>)),
                ('model', LogisticRegression(C=1, n_jobs=-1, random_state=42))])
2021-12-08 04:32:40,820 [DEBUG] Best parameters:
2021-12-08 04:32:40,820 [DEBUG] {'model__C': 1, 'model__n_jobs': -1, 'model__penalty': 'l2', 'model__random_state': 42, 'model__solver': 'lbfgs', 'vectorizer__ngram_range': (1, 2), 'vectorizer__tokenizer': <__main__.WordTokenizer object at 0x7ff2d951e3a0>}
2021-12-08 04:32:40,821 [DEBUG] Best (f1) score:
2021-12-08 04:32:40,821 [DEBUG] 0.9769578614683553
2021-12-08 04:34:46,180 [DEBUG] Val set results of the best classifier:
2021-12-08 04:34:48,090 [DEBUG]               precision    recall  f1-score   support

           0       1.00      0.95      0.97        56
           1       0.97      1.00      0.99        36
           2       0.95      0.97      0.96        40
           3       0.98      1.00      0.99        54
           4       0.97      0.97      0.97        36

    accuracy                           0.98       222
   macro avg       0.98      0.98      0.98       222
weighted avg       0.98      0.98      0.98       222

2021-12-08 04:34:48,327 [DEBUG] [[53  0  2  0  1]
 [ 0 36  0  0  0]
 [ 0  0 39  1  0]
 [ 0  0  0 54  0]
 [ 0  1  0  0 35]]
